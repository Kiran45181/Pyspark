{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODwiWKwGWz6ls3gDqbghC6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kiran45181/Pyspark/blob/main/Advanced_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi9Qr-1kB99f",
        "outputId": "612c20d5-fa92-4d5b-b6e6-40a8cc20f2ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+\n",
            "| id| name|department|salary|\n",
            "+---+-----+----------+------+\n",
            "|  1|Alice|        HR|  3000|\n",
            "|  2|  Bob|        IT|  4000|\n",
            "|  3|Cathy|        HR|  3500|\n",
            "|  4|David|        IT|  4500|\n",
            "|  5|  Eve|   Finance|  5000|\n",
            "|  6|Frank|   Finance|  4800|\n",
            "+---+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark Use Case Activities\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "from pyspark.sql.functions import col, rank, avg, udf, pandas_udf\n",
        "from pyspark.sql.window import Window\n",
        "import pandas as pd\n",
        "\n",
        "employees_data = [\n",
        "    (1, \"Alice\", \"HR\", 3000),\n",
        "    (2, \"Bob\", \"IT\", 4000),\n",
        "    (3, \"Cathy\", \"HR\", 3500),\n",
        "    (4, \"David\", \"IT\", 4500),\n",
        "    (5, \"Eve\", \"Finance\", 5000),\n",
        "    (6, \"Frank\", \"Finance\", 4800),\n",
        "]\n",
        "\n",
        "employees_df = spark.createDataFrame(employees_data, [\"id\", \"name\", \"department\", \"salary\"])\n",
        "employees_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, col\n",
        "\n",
        "# Define window: partition by department and order by salary descending\n",
        "window_spec = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
        "\n",
        "# Apply rank\n",
        "ranked_df = employees_df.withColumn(\"rank\", rank().over(window_spec))\n",
        "\n",
        "ranked_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-JN2LFcCZIz",
        "outputId": "f32a1d7d-a814-47c7-bf44-50fc65ce1d8b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+----+\n",
            "| id| name|department|salary|rank|\n",
            "+---+-----+----------+------+----+\n",
            "|  5|  Eve|   Finance|  5000|   1|\n",
            "|  6|Frank|   Finance|  4800|   2|\n",
            "|  3|Cathy|        HR|  3500|   1|\n",
            "|  1|Alice|        HR|  3000|   2|\n",
            "|  4|David|        IT|  4500|   1|\n",
            "|  2|  Bob|        IT|  4000|   2|\n",
            "+---+-----+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "# Define window spec: partition by department (no order needed for average)\n",
        "window_spec = Window.partitionBy(\"department\")\n",
        "\n",
        "# Calculate average salary per department\n",
        "avg_salary_df = employees_df.withColumn(\n",
        "    \"avg_salary_per_dept\", avg(\"salary\").over(window_spec)\n",
        ")\n",
        "\n",
        "avg_salary_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2xQkyQVCZrw",
        "outputId": "38522011-7f36-4b00-9e86-073f19d41670"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+-------------------+\n",
            "| id| name|department|salary|avg_salary_per_dept|\n",
            "+---+-----+----------+------+-------------------+\n",
            "|  5|  Eve|   Finance|  5000|             4900.0|\n",
            "|  6|Frank|   Finance|  4800|             4900.0|\n",
            "|  1|Alice|        HR|  3000|             3250.0|\n",
            "|  3|Cathy|        HR|  3500|             3250.0|\n",
            "|  2|  Bob|        IT|  4000|             4250.0|\n",
            "|  4|David|        IT|  4500|             4250.0|\n",
            "+---+-----+----------+------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Practice"
      ],
      "metadata": {
        "id": "eHsQoGdHboFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "#create a emp table with salary dept\n",
        "emp_data = [(\"James\", \"Sales\", 3000), (\"Michael\", \"Sales\", 4600), (\"Robert\", \"Sales\", 4100), (\"Maria\", \"Finance\", 3000), (\"James\", \"Sales\", 3900)]\n",
        "\n",
        "\n",
        "column = [\"name\", \"dept\", \"salary\"]\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SparkByExamples\").getOrCreate()\n",
        "\n",
        "emp_df = spark.createDataFrame(emp_data, column)\n",
        "emp_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6L1r6QRDvy8",
        "outputId": "e699797b-e7b0-45ce-f6f6-0c2f4812eb2f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+------+\n",
            "|   name|   dept|salary|\n",
            "+-------+-------+------+\n",
            "|  James|  Sales|  3000|\n",
            "|Michael|  Sales|  4600|\n",
            "| Robert|  Sales|  4100|\n",
            "|  Maria|Finance|  3000|\n",
            "|  James|  Sales|  3900|\n",
            "+-------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create dept dataset\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SparkByExamples\").getOrCreate()\n",
        "\n",
        "dept_data = [(\"Finance\", 10), (\"Marketing\", 20), (\"Sales\", 30), (\"IT\", 40)]\n",
        "\n",
        "dept_columns = [\"dept\", \"dept_id\"]\n",
        "\n",
        "dept_df = spark.createDataFrame(dept_data, dept_columns)\n",
        "dept_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZprlhYCLcqcm",
        "outputId": "3537037e-1b78-4fbd-881b-f6022e51fe12"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|     dept|dept_id|\n",
            "+---------+-------+\n",
            "|  Finance|     10|\n",
            "|Marketing|     20|\n",
            "|    Sales|     30|\n",
            "|       IT|     40|\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df.join(dept_df, \"dept\", \"inner\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OKnKZFddWOG",
        "outputId": "1a234800-24c9-4b0e-85c7-de7c798835ca"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+------+-------+\n",
            "|   dept|   name|salary|dept_id|\n",
            "+-------+-------+------+-------+\n",
            "|Finance|  Maria|  3000|     10|\n",
            "|  Sales|  James|  3000|     30|\n",
            "|  Sales|Michael|  4600|     30|\n",
            "|  Sales| Robert|  4100|     30|\n",
            "|  Sales|  James|  3900|     30|\n",
            "+-------+-------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df.select(\"Name\",\"salary\").orderBy(col(\"salary\").desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKKOg3sWdtMb",
        "outputId": "5b7ecf6b-9a27-4596-a8e0-ca027d316cd8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+\n",
            "|   Name|salary|\n",
            "+-------+------+\n",
            "|Michael|  4600|\n",
            "| Robert|  4100|\n",
            "|  James|  3900|\n",
            "|  James|  3000|\n",
            "|  Maria|  3000|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df.filter(col(\"salary\")>4000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRi6LCoBfmV_",
        "outputId": "80660c9f-65b3-43f8-da7a-8cc9822f67c8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+------+\n",
            "|   name| dept|salary|\n",
            "+-------+-----+------+\n",
            "|Michael|Sales|  4600|\n",
            "| Robert|Sales|  4100|\n",
            "+-------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df.withColumn(\"bonus\", col(\"salary\")*0.1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l35B1UxAgUvi",
        "outputId": "b4ca8604-ffc2-4238-aaf8-ff8427a68ae5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+------+-----+\n",
            "|   name|   dept|salary|bonus|\n",
            "+-------+-------+------+-----+\n",
            "|  James|  Sales|  3000|300.0|\n",
            "|Michael|  Sales|  4600|460.0|\n",
            "| Robert|  Sales|  4100|410.0|\n",
            "|  Maria|Finance|  3000|300.0|\n",
            "|  James|  Sales|  3900|390.0|\n",
            "+-------+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"WindowPractice\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, \"Alice\", \"HR\", 3000),\n",
        "    (2, \"Bob\", \"IT\", 4000),\n",
        "    (3, \"Cathy\", \"HR\", 3500),\n",
        "    (4, \"David\", \"IT\", 4500),\n",
        "    (5, \"Eve\", \"Finance\", 5000),\n",
        "    (6, \"Frank\", \"Finance\", 4800),\n",
        "]\n",
        "\n",
        "columns = [\"id\", \"name\", \"department\", \"salary\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etBtp-cFgtUP",
        "outputId": "c816c236-23df-44be-bad1-bf8e17ae3959"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+\n",
            "| id| name|department|salary|\n",
            "+---+-----+----------+------+\n",
            "|  1|Alice|        HR|  3000|\n",
            "|  2|  Bob|        IT|  4000|\n",
            "|  3|Cathy|        HR|  3500|\n",
            "|  4|David|        IT|  4500|\n",
            "|  5|  Eve|   Finance|  5000|\n",
            "|  6|Frank|   Finance|  4800|\n",
            "+---+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, col\n",
        "window_spec = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
        "\n",
        "df.withColumn(\"rank\",rank().over(window_spec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-eNdtr_haos",
        "outputId": "b2603a7e-e04f-4f71-c867-3223a9923972"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+----+\n",
            "| id| name|department|salary|rank|\n",
            "+---+-----+----------+------+----+\n",
            "|  5|  Eve|   Finance|  5000|   1|\n",
            "|  6|Frank|   Finance|  4800|   2|\n",
            "|  3|Cathy|        HR|  3500|   1|\n",
            "|  1|Alice|        HR|  3000|   2|\n",
            "|  4|David|        IT|  4500|   1|\n",
            "|  2|  Bob|        IT|  4000|   2|\n",
            "+---+-----+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SowofBlCiPZU"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Complex Nested Schema Handling"
      ],
      "metadata": {
        "id": "EkaufKJAje8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AdvancedOps\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (\"John\", [\"Python\", \"Java\"]),\n",
        "    (\"Jane\", [\"SQL\", \"R\", \"Scala\"]),\n",
        "    (\"Mike\", [])\n",
        "]\n",
        "columns = [\"Name\", \"Skills\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enZ2Udp-kDXh",
        "outputId": "6e97117b-dc60-4070-f91d-2489638e762e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------------+\n",
            "|Name|Skills         |\n",
            "+----+---------------+\n",
            "|John|[Python, Java] |\n",
            "|Jane|[SQL, R, Scala]|\n",
            "|Mike|[]             |\n",
            "+----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_explode = df.withColumn(\"Skills\",explode(df.Skills))\n",
        "df_explode.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrrkCzUikFOl",
        "outputId": "4d795383-5a3b-414f-e9b6-c66af1a3b280"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+\n",
            "|Name|Skills|\n",
            "+----+------+\n",
            "|John|Python|\n",
            "|John|  Java|\n",
            "|Jane|   SQL|\n",
            "|Jane|     R|\n",
            "|Jane| Scala|\n",
            "+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"people\")\n"
      ],
      "metadata": {
        "id": "nNAv88sokQxE"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lateral = spark.sql(\"\"\"\n",
        "    SELECT Name, Skill\n",
        "    FROM people\n",
        "    LATERAL VIEW explode(Skills) AS Skill\n",
        "\"\"\")\n",
        "\n",
        "df_lateral.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3l0Vf74lhD1",
        "outputId": "40bc5bc2-10d9-4d0e-a362-2061f8b5e574"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+\n",
            "|Name| Skill|\n",
            "+----+------+\n",
            "|John|Python|\n",
            "|John|  Java|\n",
            "|Jane|   SQL|\n",
            "|Jane|     R|\n",
            "|Jane| Scala|\n",
            "+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pivot"
      ],
      "metadata": {
        "id": "4xjOGYLKya-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"ProductA\", \"Jan\", 100),\n",
        "    (\"ProductA\", \"Feb\", 150),\n",
        "    (\"ProductA\", \"Mar\", 120),\n",
        "    (\"ProductB\", \"Jan\", 200),\n",
        "    (\"ProductB\", \"Feb\", 230),\n",
        "    (\"ProductB\", \"Mar\", 210),\n",
        "]\n",
        "columns = [\"Product\", \"Month\", \"Sales\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li4ftlCemEiD",
        "outputId": "c0cc7fc8-00ac-4263-ccfb-7fe45e5443dd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+-----+\n",
            "| Product|Month|Sales|\n",
            "+--------+-----+-----+\n",
            "|ProductA|  Jan|  100|\n",
            "|ProductA|  Feb|  150|\n",
            "|ProductA|  Mar|  120|\n",
            "|ProductB|  Jan|  200|\n",
            "|ProductB|  Feb|  230|\n",
            "|ProductB|  Mar|  210|\n",
            "+--------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df = df.groupBy(\"Product\").pivot(\"Month\").sum(\"Sales\")\n",
        "pivot_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8GvQetxygNi",
        "outputId": "9e1335d0-b12b-48a6-ef6d-f8fb3d12cefc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+---+---+\n",
            "| Product|Feb|Jan|Mar|\n",
            "+--------+---+---+---+\n",
            "|ProductB|230|200|210|\n",
            "|ProductA|150|100|120|\n",
            "+--------+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#First use pivot to create wide format\n",
        "wide_df = df.groupBy(\"Product\").pivot(\"Month\").sum(\"Sales\")\n",
        "\n",
        "\n",
        "#Then unpivot back to long format\n",
        "unpivot_df = wide_df.selectExpr(\"Product\", \"stack(3, 'Jan', Jan, 'Feb', Feb, 'Mar', Mar) as (Month, Sales)\")\n",
        "\n",
        "unpivot_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udrlMqctytoB",
        "outputId": "3f081eaf-ef5f-4386-84c0-2a71dac5e2a9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+-----+\n",
            "| Product|Month|Sales|\n",
            "+--------+-----+-----+\n",
            "|ProductB|  Jan|  200|\n",
            "|ProductB|  Feb|  230|\n",
            "|ProductB|  Mar|  210|\n",
            "|ProductA|  Jan|  100|\n",
            "|ProductA|  Feb|  150|\n",
            "|ProductA|  Mar|  120|\n",
            "+--------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxNtsr0y0MDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}